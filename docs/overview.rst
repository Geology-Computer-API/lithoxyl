Lithoxyl Overview
=================

The Lithoxyl approach to application instrumentation is a practical
one. First, write your code. Then, once you have half a module or find
yourself asking, "How long does this part take?" then it's time to
``pip install lithoxyl``. There are two steps. First comes
instrumentation, then we select a configuration.

Application instrumentation
---------------------------

With Lithoxyl, logging and other instrumentation starts with knowing
your application. We want to find the important parts of your
application, and wrap them in microtransactions called
``Records``. Records can be created directly, but they are most often
created through ``Loggers``.

Let's take a look::

  import backend           # some convenient backend logic for brevity
  from log import app_log  # preconfigured Lithoxyl Logger

  def create_entry(name):
      with app_log.info('adding entry by name'):
          name = name.strip()
          backend.add_by_name(name)
      return True

As you can see, the transactionality of records translates well to
Python's :term:`with` context manager syntax. One benefit of this
approach is that a single line of logging code is able to record both
the start and end events. Even better is that there is no chance of
missing an exception if one is raised unexpectedly. For instance, if
*name* is not a string, and ``.strip()`` raises an ``AttributeError``,
then that exception is guaranteed to be recorded.

Records also support direct interaction. Arbitrary data can be added
to the record, with dictonary syntax. And while records finish with a
success status and autogenerated message if no exception is raised,
failures and exceptions can also be set manually::

  import backend
  from log import app_log

  def set_entry_state(name, state):
      with app_log.info('setting entry state') as rec:
          rec['name'] = name
          status = backend.STATE_MAP[state.lower()]
          success = backend.set_entry_state(name, state)
          if not success:
              rec.failure('set {name} status to {state} failed', state=state)
       return success

As seen above, records can also have a custom completion message,
which supports templating with new-style formatting syntax, using data
from within the record's data map (*name*), as well as arguments and
keyword arguments (*state*).

.. note::

   Even if message formatting fails, the log message will degrade
   gracefully. As a rule, Lithoxyl degrades gracefully, to minimize
   impact to your application's primary functionality.

Furthermore, in cases like this, where you want the whole function
logged, you can simply do::

  import backend
  from log import app_log

  @app_log.wrap('critical', inject_as='rec')
  def delete_entry(name, rec):
      try:
          ret = backend.delete_entry_by_name(name.strip())
      except backend.EntryNotFound:
          # log soft error, let other exceptions raise through
          log_rec.failure('no entry with name: {}', name)
          ret = False
      return ret

Note the decorator syntax, as well as the ability to inject the log
record as one of the arguments of the function. This reduces the
instrumentation's code footprint even further.

That about covers creating and interacting with records. Now we turn
to the origin and destination of the records we create and populate:
Loggers and Sinks.

Logger and Sink configuration
-----------------------------

Logger creation
~~~~~~~~~~~~~~~

As we learned above, Records come from Loggers. This is nearly half of
what Loggers do. Half the functionality of a Logger takes only one line::

  from lithoxyl import Logger

  app_log = Logger('entry_system')

Like that, the Logger is created and ready to be imported. A Logger
only requires a name. Given this simplicity, it's safe to say Loggers
are lightweight, simple objects, but they are conceptually very
useful.

A Logger generally corresponds to an aspect of the system. As such,
they are designed to be created once, configured, and imported by
other modules. Applications usually starts out with one high level log.

As applications grow, they tend to add aspects. Small- to medium-sized
applications can go pretty far with just one Logger, but larger
applications benefit from multiple. For example, if file access grows
increasingly important to an application, it would make sense to add a
dedicated low-level log just for instrumenting file access::

  file_log = Logger('file_access')

In short, Loggers themselves are simple, and designed to fit your
application, no matter how many aspects it may have.

Sink configuration
~~~~~~~~~~~~~~~~~~

So far, we have discovered two uses of the Lithoxyl Logger:

  * Creating log records
  * Segmenting and naming aspects of an application

Now, we are ready to add the third: publishing log events to the
appropriate handlers, called Sinks. Records can carry all manner of
messages and measurements. That variety is only surpassed by the
Sinks, which handle aggregation and persistence, through log files,
network streams, and much more. Before getting into those
complexities, let's configure our ``app_log`` with a simple but very
useful sink::

  from lithoxyl import AggregateSink

  agg_sink = AggregateSink(limit=100)
  app_log.add_sink(agg_sink)

Now, by adding an instance of the AggregateSink to the ``app_log``, we
have a technically complete system. At any given point after this, the
last 100 events that passed through our application log will be
available inside ``agg_sink``. However, AggregateSinks only provide
in-memory storage, meaning data must be pulled out, either through a
monitoring thread or network service. Most developers expect
persistent logging to streams (stdout/stderr) and files. Lithoxyl is
more than capable.

Sensible logging
^^^^^^^^^^^^^^^^

For developers who want a sensible and practical default, Lithoxyl
provides the SensibleSink. See The Sensible Suite for a full
introduction.

In short, the SensibleSink aims to create human-readable structured
logs. Structured logs are logs which can be automatically parsed. This
allows logs to be loaded for further processing steps, such as
collation with other logs, ETL into OLAP and other databases, and
calculation of system-wide statistics. Extending the flow of logged
information opens up many new roads in debugging, optimization, and
system robustification.

Numeric Sinks
^^^^^^^^^^^^^

Sink internals
~~~~~~~~~~~~~~

Lithoxyl aims to provide a sufficient set of Sinks for most
small-to-medium use cases. That said, creating new Sinks is
straightforward and encouraged.

Events
^^^^^^

Sinks are objects designed to handle events. Lithoxyl currently has
five event types, and Sinks can handle them by implementing one or
more of the following methods:

  * ``on_begin(self, begin_event)`` - Called whenever a Record begins,
    whether manually or through entering the context managed block of
    code. Designed to be called once per Record.
  * ``on_end(self, end_event)`` - Called whenever a Record completes,
    whether manually through ``success()`` or ``failure()``, through
    exiting the context-managed block, or through an exception being
    raised from within the context-managed block. Designed to be
    called once per Record.
  * ``on_warn(self, warn_event)`` - Called whenever Record.warn() is
    called. Can be called an arbitrary number of times.
  * ``on_comment(self, comment_event)`` - Called whenever
    Record.comment() is called. Can be called an arbitrary number of
    times.
  * ``on_exception(self, exc_event, exc_type, exc_obj, exc_tb)`` -
    Called when an exception is raised from within the context-managed
    block, or when an exception is manually handled with
    Record.exception(). Designed to be called up to once.

Event objects are meant to be practically-immutable objects, only
having their values set once at creation.
